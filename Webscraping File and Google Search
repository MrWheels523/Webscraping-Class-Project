# pip install urllib3
from urllib.request import urlopen as uReq

# pip install bs4
from bs4 import BeautifulSoup as soup

# pip install prettyprinter
from prettyprinter import pprint

my_url = 'https://www.newegg.com/p/pl?d=computer'

# Downloads URL and moves it into the page_html file
uClient = uReq(my_url)
page_html = uClient.read()
uClient.close()

# Parses html file
page = soup(page_html, "html.parser")

# Finds all headline posts 
container = page.findAll("id",{"suggestion"})


container

import bs4
from urllib.request import urlopen as uReq
from bs4 import BeautifulSoup as soup
my_url = 'https://www.newegg.com/p/pl?d=computer'
uClient = uReq(my_url)
page_html = uClient.read()
uClient.close()

filename = 'products.csv'
f = open(filename, "w")
headers = "brand, product_name, shipping\n"
f.write(headers)
page_soup = soup(page_html, "html.parser")
contaners = page_soup.findAll("div", {"class":"item-conatiner"})
for container in containers: 
#     brand = container.div.div.a.img["title"]
    title_container = container.findAll("a", {"class":"item-title"})
    product_name = title_container[0].text
    shipping_container = container.findAll("li", {"class": "price-ship"})
    shipping = shipping_container[0].text.strip()
    print("brand", brand)
    print("product name:", product_name)
    print("shipping", shipping)
    f.write(brand + "," + product_name.replace(",", "|") + "," + shipping + "\n")
    
f.close()

from googlesearch import search
query = input("Search query:")
for i in search(query, tld="com", num = 10, stop=10, pause=2):
    print(i)
